{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfec658",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e8739",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e6f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f657ede7",
   "metadata": {},
   "source": [
    "**`%matplotlib notebook`**\n",
    "\n",
    "Unlike `%matplotlib inline`, which displays static images of plots, `%matplotlib notebook` provides an interactive interface with the plots, allowing for zooming, panning, and other interactive features. It can be useful for exploring and analyzing data in a more interactive manner. However, it may be slower and more resource-intensive than %matplotlib inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674c611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None # to remove the limit on the number of df columns shown in output\n",
    "pd.options.display.precision = 3 # to have 3 decimal points as a global option in dataframes\n",
    "pd.options.display.float_format = '{:,.3f}'.format # 3 decimals and ',' for larger floats in pd dataframes\n",
    "np.set_printoptions(precision = 3) # to have 3 decimal points as a global option in simple print outputs\n",
    "np.set_printoptions(suppress = True) # to avoid scientific notation in the outputs\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{:,.3f}\".format(x)}) # 3 decimals and ',' for larger floats in np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524b1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing = pd.read_csv(\"https://raw.githubusercontent.com/monahatami1/monogram1/master/USA_Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ac5e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing.isnull().sum() # checking if there is any null values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c97f42",
   "metadata": {},
   "source": [
    "I don't like column heads that are so long! So I am going to change those to 1-2 words maximum length. It will easier to handle if shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColNames = \"Income Age Rooms BedroomArea Population Price Address\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing = pd.read_csv(\"https://raw.githubusercontent.com/monahatami1/monogram1/master/USA_Housing.csv\", \n",
    "                      skiprows = 1,\n",
    "                     names = ColNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b481b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format # 1 decimal points and ',' for larger floats in Pandas dataframes\n",
    "Housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046515d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524584f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Housing.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c250b",
   "metadata": {},
   "source": [
    "Just to have some fun with categorical variables as well, I am going to create some categorical variable out of the existing variables. Let's make a binary and a multi-class variable. I will just use the 40,000 as the population threshold to call it an MPO and this shall become an indicator factor variable with Yes and No as the values. \n",
    "Similarly, for Rooms, let's call them Low (rooms less than 4), Medium (for 4-7 rooms) and High (for more than 7 rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb879f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing['MPO'] = Housing['Population'].apply(lambda x: \"Yes\" if x >= 40000 else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a482a6eb",
   "metadata": {},
   "source": [
    "The .apply() function is a method in pandas that applies a function along an axis of the DataFrame. I used it above to apply a lambda function to each value of the Population column. The lambda function takes a single argument x, which represents each population value and if it is greater than or equal to 40000, the function returns \"Yes\", otherwise it returns \"No\" in the new column defined as MPO.\n",
    "\n",
    "I could simply use 1 and 0 instead of Yes and No, but I did it so that below I can practice the `.cat.codes` attribute below.\n",
    "This attribute in pandas can be used to get the integer codes of the categories in a categorical column. **This attribute is available only for pandas categorical columns, which are created using the `pd.Categorical()` function or by calling the `.astype('category')` method on an existing column.** \n",
    "\n",
    "For practice purposes I will create a new column with the codes this time. Note, the new MPO column is not defined as categorical so it has to be identified as categorical first before coding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75dbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing['MPO01'] = Housing['MPO'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4a8416",
   "metadata": {},
   "outputs": [],
   "source": [
    "RoomGroups = 'Low Medium High'.split() # define groups to put numbers in\n",
    "Room_bins = np.linspace(min(Housing[\"Rooms\"]), max(Housing[\"Rooms\"]), 4) # define bins betwen min and max to use to split\n",
    "Housing['RoomGroup'] = pd.cut(Housing['Rooms'], \n",
    "                                bins = Room_bins, \n",
    "                                right = False, # whether the interval should be closed on the right\n",
    "                                include_lowest = True, # whether the lowest edge of the leftmost bin should be included.\n",
    "                                labels = RoomGroups)\n",
    "# Housing[['Rooms', 'RoomGroup']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60540bce",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a35d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.histplot(data = Housing['Price'], \n",
    "             bins = 20,\n",
    "             kde = True,\n",
    "             color = \"red\",\n",
    "             fill = \"blue\",\n",
    "             line_kws = {'color': 'red', \n",
    "                         'linewidth': 2,\n",
    "                        'linestyle': \"-.\"})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85163ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple scatter plot of price vs one predictor variable\n",
    "Housing.plot(kind = 'scatter', \n",
    "             x = 'Income', \n",
    "             y = 'Price', \n",
    "             s = 1, \n",
    "             c = \"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7387b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a side-by-side boxplot for the Price grouped by the levels of the created binary MPO variable \n",
    "sns.boxplot(x = 'MPO01', y = 'Price', data = Housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3bf91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatter plots of all pairs of variables\n",
    "sns.pairplot(Housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a look at the correlation between variables\n",
    "corrmatrix = Housing.iloc[:,0:5].corr()\n",
    "corrmatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a67af9",
   "metadata": {},
   "source": [
    "Let's look at the correlation matrix in a heat map. Some of the options for the color map are viridis, coolwarm, magma, inferno, plasma, Greys, Blues, Greens, Reds, Oranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de445cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corrmatrix, \n",
    "            cmap = 'Reds', # color map\n",
    "            annot = True, # add numeric values\n",
    "            linewidth = 0.1,\n",
    "            linecolor = \"black\"\n",
    "           ) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2288e5a",
   "metadata": {},
   "source": [
    "## Training\n",
    "We need predictors and a target. In this case, the target is the house price and the other variables are being used as predictors. Address is also not used assuming it does not provide any additional informaiton on the Price. It may do, if we could extarct zip codes or street names but for now, this column is out!\n",
    "\n",
    "**1.** Divide dataset into train and test sets using **`train_test_split`** function from `scikit-learn` library's `model_selection` module\n",
    "\n",
    "The syntax is `train_test_split(X, y, test_size = None, random_state = None, shuffle = True, stratify = None)`. \n",
    "- `test_size` with a default of 0.25 represents the proportion of the dataset to include in the test split.\n",
    "- `random_state` is like a seed thing\n",
    "- `shuffle` is to whether or not sshuffle the data before splitting\n",
    "- `stratify` ensures that each class is represented proportionally in the train and test datasets.  This is useful when dealing with imbalanced datasets or when the target variable is categorical. here is an example: \n",
    "\n",
    "`X_train, X_test, y_train, y_test = train_test_split(data.drop('class', axis=1), data['class'], test_size=0.3, random_state=42, stratify=data['class'])`\n",
    "\n",
    "\n",
    "**2.** Create a regression model using **`LinearRegression`** function from `scikit-learn` library's `linear_model` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bd933",
   "metadata": {},
   "outputs": [],
   "source": [
    "Housing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0360f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColIDs = list(range(0,5)) + [8] # including the MPO Bindary variable with population is redundant (did it for coding purposes)\n",
    "X = Housing.iloc[:, ColIDs] # Defining the predictor variables\n",
    "y = Housing['Price'] # Defining the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3277b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.get_dummies(Housing['RoomGroup']) # If I wanted to use the RoomGroup I made in my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression # to make the function simepler to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 101)\n",
    "TestData = pd.concat([X_test, y_test], axis = 1)\n",
    "TrainData = pd.concat([X_train, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682e02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967442ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the Price vs. Income for train and test data visually to see how it looks!\n",
    "plt.scatter(X_train['Income'], y_train, \n",
    "            label = \"Train Data\",\n",
    "            color = \"r\", \n",
    "            marker = '.',\n",
    "            s = 2)\n",
    "\n",
    "plt.scatter(X_test['Income'], y_test, \n",
    "            label = \"Test Data\",\n",
    "            color = \"b\", \n",
    "            marker = '.',\n",
    "            s = 2,\n",
    "            alpha = 0.6)\n",
    "plt.legend()\n",
    "plt.title(\"Price vs. Income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7868e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)  # to fit the regression model to the training dataset\n",
    "print(lm.intercept_)\n",
    "pd.DataFrame(data = list([lm.intercept_]) + list(lm.coef_), \n",
    "             index = ['Intercept'] + list(X.columns), \n",
    "             columns = ['Coefficient'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a839117",
   "metadata": {},
   "source": [
    "## Testing and Evaluation\n",
    "For testing the model, we will use the fitted model to predict target values on the test set and then compare predictions with observed values to find error rates. There are different metrics or loss functions that can be used for evaluating the fit, as we try to minimize them with better models that predict better.\n",
    "- **Mean Absolute Error**, (the average error / the easiest to understand)\n",
    "- **Mean Squared Error**, (more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in real world)\n",
    "- **Root Mean Squared Error** (even more popular than MSE, because RMSE is interpretable in the \"y\" units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85798478",
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b84ee",
   "metadata": {},
   "source": [
    "In ML, the method `.reshape(1, -1)` is used to transform a 1-dimensional numpy array (`np.array()`) into a 2-dimensional array with 1 row and a number of columns equal to the length of the original array. This is often used to prepare data for model training or prediction, as many ML algorithms expect 2-dimensional arrays as input. **The -1 argument in the reshape method is used to automatically calculate the number of columns based on the length of the original array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict the price of a specific house with certain values for its predictors\n",
    "SampleHouse = np.array([68500, 5.9, 6.9, 3.4, 3600, 1]).reshape(1,-1)\n",
    "SampleHouseprice = lm.predict(SampleHouse)\n",
    "print('Predicted price for the sample house is ${0}'.format(round(SampleHouseprice[0], 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d237042",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, Predictions, \n",
    "            marker = '.', \n",
    "            c = \"red\", \n",
    "            s = 1)\n",
    "plt.title('Predicted vs. Observed House Prices') ; plt.xlabel('Observed') ; plt.ylabel('Predicted'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be0a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot((y_test - Predictions), bins = 50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa71bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01556620",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE:', round(metrics.mean_absolute_error(y_test, Predictions), 2))\n",
    "print('MSE:', round(metrics.mean_squared_error(y_test, Predictions), 2))\n",
    "print('RMSE:', round(np.sqrt(metrics.mean_squared_error(y_test, Predictions)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349293b1",
   "metadata": {},
   "source": [
    "In additon, we can use the **R<sup>2</sup>** value as a metric for goodness of fit. the `score()` function from scikit-learn library would do the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158038a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
